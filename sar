#!/usr/bin/perl

# Copyright (c) 2024 Todd T. Fries <todd@fries.net>
#
# Permission to use, copy, modify, and distribute this software for any
# purpose with or without fee is hereby granted, provided that the above
# copyright notice and this permission notice appear in all copies.
#
# THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
# WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
# MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
# ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
# WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
# ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
# OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.

use strict;
use warnings;

use Digest::SHA1 qw(sha1_hex);
use File::Path qw(make_path);
use File::Spec;
use File::Slurp;
use File::Basename;
use Fcntl qw(SEEK_SET SEEK_CUR SEEK_END);
use Getopt::Std;
use LWP::UserAgent;
use Data::Dumper;
use MIME::Base64;
use DBI;
use DBD::Pg qw(:pg_types);
use Time::HiRes qw(sleep);
use Data::Dumper;
use ReadConf;
use JSON;

our $opt_b; # renterd bucket
our $opt_c; # config file
our $opt_d; # db name
our $opt_m; # mode
our $opt_p; # port for renterd
our $opt_r; # runner count
our $opt_s; # conf section
our $opt_t; # db type (Pg SQLite)
our $opt_v; # verbosity

# defaults
$opt_c = $ENV{HOME}."/.config/sar/conf";
$opt_d = "hashqueue";
$opt_t = "pg";
$opt_r = 20;
$opt_s = "default";

getopts('c:d:m:r:s:t:v');

if (!defined($opt_m)) {
	die "Need '-m <mode>' where <mode> is one of: t (test), x (extract), c (create)";
}
our $v;
if (defined($opt_v)) {
	$v = $opt_v;
} else {
	$v = 0;
}

my $rc = ReadConf->new();
our $conf = $rc->readconf($opt_c);

my $ua = LWP::UserAgent->new();
$ua->agent('Sia-Agent');

our $gv = { }; # global vars
$gv->{renterport} = $conf->{$opt_s}->{port};
$gv->{renterpass} = $conf->{$opt_s}->{pass};
$gv->{renterbucket} = $conf->{$opt_s}->{bucket};

if (defined $opt_p) {
	$gv->{renterport} = $opt_p;
}
if (defined $opt_b) {
	$gv->{renterbucket} = $opt_b;
}

# Configuration
my $block_size = 8 * 1024;
my $archive_dir = '/nhome/todd/sarchive';
my $hashes_dir = $archive_dir . "/hashes";

# Create archive dir if it doesn't exist
make_path($archive_dir) unless -d $archive_dir;
make_path($hashes_dir) unless -d $hashes_dir;

our $hdrsize = length(mkheader("ptr",""));

# memory data
our $ablk = { };
init_ablk();

# for run queue
our $maxrunners = $opt_r;
our $max_cached_blocks = 128*1024;
our $rid; # runner id
our $pid; # process id

my $db_type = $opt_t;

my $db_user = "";
my $db_pass = "";
our $dbp = { };
$dbp->{db_name} = $opt_d;
$dbp->{tb_name} = "bq";
$dbp->{db_user} = "";
$dbp->{db_pass} = "";
$dbp->{timeout} = 100; # in secondts
if ($db_type eq "sqlite") {
	$dbp->{sqlname} = "SQLite";
	$dbp->{serial} = "INTEGER PRIMARY KEY";
	$dbp->{blobname} = "BLOB";
	$dbp->{pragmas}->{busy_timeout} = 1000*$dbp->{timeout};
	$dbp->{pragmas}->{journal_mode} = "WAL";
	$dbp->{pragmas}->{synchronous} = "NORMAL";
}
if ($db_type eq "pg") {
	$dbp->{sqlname} = "Pg";
	$dbp->{serial} = "SERIAL";
	$dbp->{blobname} = "BYTEA";
}

# db store
our $dbh;

our ($qbsth,$ubsth,$rmsth);

if ($opt_m eq "c") {
	db_init("dbi:".$dbp->{sqlname}.":".$dbp->{db_name}, $db_user, $db_pass);
	foreach my $path (@ARGV) {
		print "Processing $path\n";
		if (-f $path || $path eq "-") {
			my $sha = archive_file($path);
			print $sha . "\n";
			next;
		}
		#if (-d $path) {
		#	process_dir($path);
		#	next;
		#}
	}
	exit(0);
}

our $auth = "Basic " . encode_base64(":".$gv->{renterpass},"");


if ($opt_m eq "put") {
	my $file = $ARGV[0];
	my $file_content = read_file($file);

	my $res = put($gv->{renterport},
		'api/worker/objects/name',
		$gv->{renterbucket},
		$file_content,
		$auth);
	print Dumper($res);
	exit(0);
}

if ($opt_m eq "x") {
	db_init("dbi:".$dbp->{sqlname}.":".$dbp->{db_name}, $db_user, $db_pass);
	foreach my $sha (@ARGV) {
		print "Extracting $sha\n";
		restore_file($sha);
	}
	exit(0);
}

if ($opt_m eq "t") {
	my $path = $ARGV[0];
	my $res = get($gv->{renterport},
		'api/bus/objects/'.$path,
		$gv->{renterbucket},
		{ },
		$auth);
	print "test res: ".Dumper($res);
	exit(0);
}
if ($opt_m eq "d") {
	my $path = $ARGV[0];
	my $res = delo($path);
	print "del res: ".Dumper($res);
	exit(0);
}
if ($opt_m eq "l") {
	my $path = $ARGV[0];
	my $res = listo($path, "");

	exit(0);
}


if ($opt_m eq "rq") { # run queue
	#use Proc::Daemon;
	#Proc::Daemon->init;
	my @pids;
	for $rid (1..$maxrunners) {
		my $fid = fork();
		if ($fid == 0) {
			$0 = "sar runner[$rid]";
			printf "rid %2d starting (pid $$)\n", $rid;
			db_init("dbi:".$dbp->{sqlname}.":".$dbp->{db_name}, $db_user, $db_pass);
			while(1) {
				my $count = run_queue(100);
				printf "rid %2d Uploaded $count blocks\n", $rid;
				if (count_cache() < $maxrunners) {
					sleep(2);
				}
			}
			exit(0);
		}
		push @pids,$fid;
	}
	foreach my $kid (@pids) {
		my $ret = waitpid($kid,0);
		if ($v>0) {
			print "waitpid($kid,0) returned $ret\n";
		}
	}
	exit(0);
}


print "unsupported mode: ${opt_m}\n";
exit(1);

# types of blocks
# dir -> file metadata + pointer
# pointer -> list of blocks
# data -> contents of file


# XXX need to create pointers on the fly vs after all data blocks
#  700mb file took over 15mb of memory

sub archive_file {
    my ($file_path) = @_;
    my @blocks = ();
    my $file_name;
    my $in_fh;
    if (defined($file_path) && $file_path ne "-") {
	$file_name = basename($file_path);
    	open($in_fh, '<', $file_path) or die "Cannot open $file_path: $!";
    	binmode($in_fh);
    } else {
	$in_fh = \*STDIN;
	$file_path = "-";
    }

    my $block_index = 0;
    while(1) {
	my $len = read($in_fh, my $block_data, $block_size);
	printf "read %4d asked for %4d length of data = %4d\n", $len, $block_size, length($block_data);
	if (!defined($len)) {
		die "Cannot read from $file_path: $!";
	}
	if ($len == 0) {
		last;
	}

	my $block_hash = store_block($block_data);        

	add_ptr($block_hash);
    }
    
    close($in_fh);
    my $sha = close_ptr();

    my $data = "file:$file_path\n";
    $data .= "ptr:$sha\n";

    return store_block(mkheader("dir", $data));
}

# XXX turn this into a bg queue via sqlite db?
sub store_block {
	my ($block_data) = @_;
	my $block_hash = sha1_hex($block_data);
	queue_block($block_hash, $block_data);
	return $block_hash;
}
sub queue_block {
	my ($block_hash, $block_data) = @_;
	# XXX best way to not duplicate storing the same block?
	#  - separate select to see if there?
	#  - handle error if insert with constraints?
	#  ... for now, punt, and let head() catch before upload
	my $ret;
	while (1) {
		$ret = count_cache();
		if ($ret < $max_cached_blocks) {
			last;
		}
		sleep(10);
	}
	eval {
		$dbh->do("BEGIN");
		$qbsth->bind_param(1, $block_hash);
		if ($db_type eq "pg") {
			$qbsth->bind_param(2, $block_data, { pg_type => PG_BYTEA });
		} else {
			$qbsth->bind_param(2, $block_data);
		}
		$ret = $qbsth->execute();
		printf "send %4d bytes w/hash %s\n", length($block_data), $block_hash;
		my $vsth = $dbh->prepare("SELECT id,hash,data from bq where hash = ?");
		$vsth->execute($block_hash);
		my $row = $vsth->fetchrow_hashref;
		printf "vrfy %4d bytes w/hash %s\n", length($row->{data}), $row->{hash};
		$vsth->finish();
	};
	if ($@) {
		warn "Error queueing block: $@";
		return;
	}
	if (!defined($ret)) {
		$dbh->do("ROLLBACK");
		return;
	}
	$dbh->do("COMMIT");
}
sub count_cache {
	my $sql = "SELECT COUNT(id) from ".$dbp->{tb_name};
	my $sth = $dbh->prepare($sql);
	$sth->execute();
	my $count = $sth->fetchrow_array();
	return $count;
}
sub run_queue {
	my ($maxcount) = @_;
	if (!defined($maxcount)) {
		$maxcount = 1;
	}
	if ($v>0) {
		warn sprintf("rid %2d run_queue($maxcount)",$rid);
	}
	my $count=0;
	my $ret;
	my $limit = $maxcount * $maxrunners;
	eval {
		$dbh->do("BEGIN");
		$ret = $ubsth->execute($limit);
	};
	if ($@) {
		warn sprintf("rid %2d Error retrieving block: $@",$rid);
		return 0;
	}
	if (!defined($ret)) {
		$dbh->do("ROLLBACK");
		warn sprintf("rid %2d ubsth failed! $! $@",$rid);
		return 0;
	}
	$dbh->do("COMMIT");
	if ($v>0) {
		warn sprintf("rid %2d ubsth->execute($limit) returned $ret",
			$rid);
	}
	while (my $row = $ubsth->fetchrow_hashref) {
		my $id = $row->{id};
		# avoid locking, just only upload when id % maxrunners == runner id
		my $bucket = $id % $maxrunners;
		if ( $bucket != ($rid-1)) {
			if ($v>1) {
			printf "rid %2d row %5d bail %2d % $maxrunners) = $bucket != ".($rid-1)."\n", $rid, $row->{id}, $id;
			}
			next;
		}
		$0 = sprintf("sar runner[%2d] %4d %s", $rid, $row->{id}, $row->{hash});
		printf "rid %2d row %5d handle %4d %s\n", $rid, $row->{id}, length($row->{data}), $row->{hash};;
		$count++;
		my $ret = upload_block($row->{hash}, $row->{data});
		if ($ret) {
			dequeue($row->{id});
		}
		$0 = "sar runner[$rid]";
	}
	return $count;
}
sub dequeue {
	my ($id) = @_;

	my $timeout = $dbp->{timeout};
	my $start_time = time();
	my $retry_count = 0;

	if ($v>0) {
		print "rid $rid $id nuke attempt\n";
	}

	my $success = 0;
	while(time() - $start_time < $timeout) {
		my $ret;
		eval {
			$dbh->do("BEGIN");
			$ret = $rmsth->execute(${id});
		};
		if ($@) {
			my $tsleep = 1.0+rand(2);
			warn "rid $rid $id Error removing ".${id}."from db: $@, will retry in ${tsleep}s";
			sleep($tsleep);
			$retry_count++;
			next;
		}
		if (!defined($ret)) {
			$dbh->do("ROLLBACK");
			next;
		}
		$dbh->do("COMMIT");
		if ($v>1) {
		print "rid $rid $id ret = $ret\n";
		}
		$success++;
		last;
	}
	my $pre = sprintf("rid %2d %5d Operation", $rid, $id);
	if ($success > 0) {
		printf "$pre succeeded after $retry_count retries.\n";
	} else {
		printf "$pre Operation failed.\n";
	}
}
sub upload_block {
	my ($block_hash, $block_data) = @_;
	my $res = head($gv->{renterport},
		'api/worker/objects/hashes/'.$block_hash,
		$gv->{renterbucket},
		$auth);
	if ($res->is_success) {
		if ($v>0) {
			print " found $block_hash, not re-uploading\n";
		}
		# XXX ? $res->header( 'last-modified' ) # 'Tue, 18 Jun 2024 06:59:03 GMT'
		# XXX ? $res->header( 'etag' ) # '"ec7d3a3630bd9e4ef2a39769b781f761"'
		# if size differs, don't say success
		if ($res->header( 'content-length' ) == length($block_data)) {
			return 1;
		}
	}
	$res = put($gv->{renterport},
		'api/worker/objects/hashes/'.$block_hash,
		$gv->{renterbucket},
		$block_data,
		$auth);
	if (!$res->is_success) {
		warn "Failed to upload $block_hash: ".$res->status_line;
		return 0;
	}
	if ($v>0) {
		print " put $block_hash\n";
	}
	return 1;
}

sub mkheader {
	my ($type, $data) = @_;
	my $str = "sartype:$type\n";
	$str .= $data;
	return $str;
}
sub init_ablk {
	$ablk->{size} = $hdrsize;
	$ablk->{data} = "";
}

sub add_ptr {
	my ($ptr) = @_;
	my $ptrlen = length($ptr);
	if (!defined($ptr)) {
		next;
	}
	if (($ptrlen + $ablk->{size}) > $block_size) {
		my $sha = store_block( mkheader("ptr", $ablk->{data}));
		init_ablk();
		add_hash($sha);
	}
	add_hash($ptr);
}
sub add_hash {
	my ($hash) = @_;
	$ablk->{data} .= $hash . "\n";
	$ablk->{size} += length($hash);
}
sub close_ptr {
	my ($ptr) = @_;
	my $sha = store_block( mkheader("ptr", $ablk->{data}) );
	init_ablk();
	return $sha;
}

sub restore_file {
    my ($archive_path) = @_;
    my $file_name = basename($archive_path);
    my $restored_file_path = File::Spec->catfile($archive_dir, $file_name . '.restored');
    
    open(my $in_fh, '<', $archive_path) or die "Cannot open $archive_path: $!";
    binmode($in_fh);
    
    open(my $out_fh, '>', $restored_file_path) or die "Cannot create $restored_file_path: $!";
    binmode($out_fh);
    
    while (my $line = <$in_fh>) {
	chomp($line);
	my $block_hash = $line;
	my $block_archive_path = File::Spec->catfile($archive_dir, $block_hash);

	open(my $block_in_fh, '<', $block_archive_path) or die "Cannot open $block_archive_path: $!";
	binmode($block_in_fh);
	    my $block_data;
    read($block_in_fh, $block_data, $block_size) or die "Cannot read from $block_archive_path: $!";
    print $out_fh $block_data;
    }

    close($in_fh);
    close($out_fh);

    return $restored_file_path;
}

sub put {
	my ($port, $cmd, $bucket, $data, $auth) = @_;

	my $baseurl = "http://[::1]:${port}/";
	my $url = $baseurl . $cmd . "?bucket=$bucket";
	my $encoded_data;
	my $req;

	my $header = [ 'Content-Type' => 'text/plain',
			'Authorization' => $auth ];

	$req = HTTP::Request->new(PUT => $url,
			$header,
			$data);

	my $res = $ua->request($req);
	return $res;
}
sub post {
	my ($port, $cmd, $bucket, $data, $auth) = @_;

	my $baseurl = "http://[::1]:${port}/";
	my $url = $baseurl . $cmd . "?bucket=$bucket";
	my $encoded_data;
	my $json = JSON->new->utf8->encode($data);
	my $req;

	my $header = [ 'Content-Type' => 'application/json',
			'Authorization' => $auth ];

	$req = HTTP::Request->new(POST => $url,
			$header,
			$json);

	my $res = $ua->request($req);
	return $res;
}

sub head {
	my ($port, $cmd, $bucket, $auth) = @_;

	my $baseurl = "http://[::1]:${port}/";
	my $url = $baseurl . $cmd . "?bucket=$bucket";
	my $encoded_data;
	my $req;

	my $header = [ 'Content-Type' => 'text/plain',
			'Authorization' => $auth ];

	$req = HTTP::Request->new(HEAD => $url,
			$header);

	my $res = $ua->request($req);
	#print Dumper($res);
	#exit(0);
	return $res;
}

sub get {
	my ($port, $cmd, $bucket, $params, $auth) = @_;

	my $baseurl = "http://[::1]:${port}/";
	my $url = $baseurl . $cmd;
	$params->{bucket} = $bucket;
	my $str = "";
	for my $var (keys %{ $params }) {
		if (length($str) < 1) {
			$str=$str."?${var}=".$params->{$var};
			next;
		}
		$str=$str."&${var}=".$params->{$var};
	}
	$url .= $str;

	my $encoded_data;
	my $req;

	my $header = [ 'Content-Type' => 'text/plain',
			'Authorization' => $auth ];

	$req = HTTP::Request->new(GET => $url,
			$header);

	my $res = $ua->request($req);
	#print Dumper($res);
	#exit(0);
	return $res;
}
sub del {
	my ($port, $cmd, $bucket, $auth) = @_;

	my $baseurl = "http://[::1]:${port}/";
	my $url = $baseurl . $cmd . "?bucket=$bucket";
	my $encoded_data;
	my $req;

	my $header = [ 'Content-Type' => 'text/plain',
			'Authorization' => $auth ];

	$req = HTTP::Request->new(DELETE => $url,
			$header);

	my $res = $ua->request($req);
	#print Dumper($res);
	#exit(0);
	return $res;
}

sub db_init {
	my ($cstr, $user, $pass) = @_;
	$dbh = DBI->connect("dbi:".$dbp->{sqlname}.":dbname=".$dbp->{db_name},
		$dbp->{db_user}, $dbp->{db_pass},{
			RaiseError => 0,
			PrintError => 0,
		}) or die "Couldn't connect to database: $DBI::errstr";
	#$dbh->trace(2);

	my $sth = $dbh->prepare("CREATE TABLE IF NOT EXISTS ".$dbp->{tb_name}." ".
		"(id ".$dbp->{serial}.", hash TEXT, data ".$dbp->{blobname}.")");
	$sth->execute() or die "Couldn't create table: $DBI::errstr";
	foreach my $pragma (keys %{ $dbp->{pragmas} }) {
		my $pcmd = "PRAGMA ".$pragma." = ".$dbp->{pragmas}->{$pragma};
		eval {
			$dbh->do($pcmd);
		};
		if ($@) {
			die "Couldn't do($pcmd): $@: $DBI::errstr";
		}
	}
	$qbsth = $dbh->prepare("INSERT INTO ".$dbp->{tb_name}." (hash, data) VALUES (?, ?)");
	$ubsth = $dbh->prepare("SELECT id,hash,data FROM ".$dbp->{tb_name}." ORDER BY id ASC LIMIT ?");
	$rmsth = $dbh->prepare("DELETE FROM ".$dbp->{tb_name}." WHERE id = ?");
}

sub fmt_objects {
	my ($objects) = @_;
	my $hidehealth = 0.7;
	for my $o (@{ $objects->{objects} }) {
		if ($o->{health} > $hidehealth) {
			next;
		}
		printf "%5f %12d %s%s\n",
			$o->{health},
			$o->{size},
			$o->{bucket},
			$o->{key};
	}
}
sub listo {
	my ($p, $n) = @_;

	my @next = ("");
	my $ncount = 0;
	my $res;
	_recurse:
	#printf "ncount %d vs nextcount %d\n", $ncount, $#next;
	while ($ncount <= $#next) {
		my $n = $next[$ncount++];
	$p =~ s/^\///;
	if (! ($p =~ /\/$/)) {
		$p .= "/";
	}
	my $params = {
		"limit" => 100,
		"prefix" => $p,
		"marker" => "",
		"recursive" => JSON::false,
		"delimiter" => "",
		"sortby" => "",
		"sortdir" => "",
		"substring" => "",
		"marker" => $n,
	};
	my $call = 'api/bus/objects/';
	$res = get($gv->{renterport},
		$call,
		$gv->{renterbucket},
		$params,
		$auth);
	#print "post res: ".Dumper($res);
	my $objects = JSON->new->utf8->decode($res->{_content});
	fmt_objects($objects);
	my $minhealth = -0.1;
	for my $o (@{ $objects->{objects} }) {
		if ($o->{health} < $minhealth) {
			delo($o->{key});
		}
	}
	#printf "next: listo(%s, %s);\n", $p, $objects->{nextMarker};
	#print "hasMore is ".Dumper($objects->{hasMore});
	if ($objects->{hasMore} == JSON::true) {
		push @next, $objects->{nextMarker};
		goto _recurse;
	}
	}
	return $res;
}
sub delo {
	my ($path) = @_;

	$path =~ s/^\///;

	printf "D %s", $path;
	my $res = del($gv->{renterport},
		'api/bus/object/'.$path,
		$gv->{renterbucket},
		$auth);
	print "\n";
	return $res;
}
