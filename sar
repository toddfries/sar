#!/usr/bin/perl

# Copyright (c) 2024 Todd T. Fries <todd@fries.net>
#
# Permission to use, copy, modify, and distribute this software for any
# purpose with or without fee is hereby granted, provided that the above
# copyright notice and this permission notice appear in all copies.
#
# THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
# WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
# MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
# ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
# WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
# ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
# OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.

use strict;
use warnings;

use Digest::SHA1 qw(sha1_hex);
use File::Path qw(make_path);
use File::Spec;
use File::Slurp;
use File::Basename;
use Fcntl qw(SEEK_SET SEEK_CUR SEEK_END);
use Getopt::Std;
use LWP::UserAgent;
use Data::Dumper;
use MIME::Base64;
use DBI;
use DBD::Pg qw(:pg_types);
use Time::HiRes qw(sleep);
use Data::Dumper;
use ReadConf;
use JSON;

our $opt_b; # renterd bucket
our $opt_c; # config file
our $opt_d; # db name
our $opt_m; # mode
our $opt_p; # port for renterd
our $opt_r; # runner count
our $opt_s; # conf section
our $opt_t; # db type (Pg SQLite)
our $opt_v; # verbosity

# defaults
$opt_c = $ENV{HOME}."/.config/sar/conf";
$opt_d = "hashqueue";
$opt_t = "pg";
$opt_r = 20;
$opt_s = "default";

getopts('b:c:d:m:r:s:t:v');

if (!defined($opt_m)) {
	die "Need '-m <mode>' where <mode> is one of: t (test), x (extract), c (create)";
}
our $v;
if (defined($opt_v)) {
	$v = $opt_v;
} else {
	$v = 0;
}

my $rc = ReadConf->new();
our $conf = $rc->readconf($opt_c);

my $ua = LWP::UserAgent->new();
$ua->agent('Sia-Agent');

our $gv = { }; # global vars
$gv->{renterport} = $conf->{$opt_s}->{port};
$gv->{renterpass} = $conf->{$opt_s}->{pass};
$gv->{renterbucket} = $conf->{$opt_s}->{bucket};
$gv->{JSON} = JSON->new->utf8();
$gv->{AUTH} = "Basic " . encode_base64(":".$gv->{renterpass},"");

if (defined $opt_p) {
	$gv->{renterport} = $opt_p;
}
if (defined $opt_b) {
	$gv->{renterbucket} = $opt_b;
}

# Configuration
my $block_size = 8 * 1024;
my $archive_dir = '/nhome/todd/sarchive';
my $hashes_dir = $archive_dir . "/hashes";

# Create archive dir if it doesn't exist
make_path($archive_dir) unless -d $archive_dir;
make_path($hashes_dir) unless -d $hashes_dir;

our $hdrsize = length(mkheader("ptr",""));

# memory data
our $ablk = { };
init_ablk();

# for run queue
our $maxrunners = $opt_r;
our $max_cached_blocks = 128*1024;
our $rid; # runner id
our $pid; # process id

my $db_type = $opt_t;

my $db_user = "";
my $db_pass = "";
our $dbp = { };
$dbp->{db_name} = $opt_d;
$dbp->{tb_name} = "bq";
$dbp->{db_user} = "";
$dbp->{db_pass} = "";
$dbp->{timeout} = 100; # in secondts
if ($db_type eq "sqlite") {
	$dbp->{sqlname} = "SQLite";
	$dbp->{serial} = "INTEGER PRIMARY KEY";
	$dbp->{blobname} = "BLOB";
	$dbp->{pragmas}->{busy_timeout} = 1000*$dbp->{timeout};
	$dbp->{pragmas}->{journal_mode} = "WAL";
	$dbp->{pragmas}->{synchronous} = "NORMAL";
}
if ($db_type eq "pg") {
	$dbp->{sqlname} = "Pg";
	$dbp->{serial} = "SERIAL";
	$dbp->{blobname} = "BYTEA";
}

# db store
our $dbh;

our ($qbsth,$ubsth,$rmsth);

if ($opt_m eq "c") {
	db_init("dbi:".$dbp->{sqlname}.":".$dbp->{db_name}, $db_user, $db_pass);
	foreach my $path (@ARGV) {
		print "Processing $path\n";
		if (-f $path || $path eq "-") {
			my $sha = archive_file($path);
			print $sha . "\n";
			next;
		}
		#if (-d $path) {
		#	process_dir($path);
		#	next;
		#}
	}
	exit(0);
}



if ($opt_m eq "put") {
	my $file = $ARGV[0];
	my $file_content = read_file($file);

	my $content = put('api/worker/objects/name',
		$file_content);
	print Dumper($content);
	exit(0);
}

if ($opt_m eq "x") {
	db_init("dbi:".$dbp->{sqlname}.":".$dbp->{db_name}, $db_user, $db_pass);
	foreach my $sha (@ARGV) {
		print "Extracting $sha\n";
		restore_file($sha);
	}
	exit(0);
}

if ($opt_m eq "t") {
	my $path = $ARGV[0];
	my $content = get('api/bus/objects/'.$path,
		{ });
	print "test res: ".Dumper($content);
	exit(0);
}
if ($opt_m eq "d") {
	my $path = $ARGV[0];
	my $content = delo($path);
	exit(0);
}
if ($opt_m eq "l") {
	my $path = $ARGV[0];
	my $content = listo($path, 0);

	exit(0);
}
if ($opt_m eq "alerts") {
	my $call = 'api/bus/alerts';
	#$call .= "?offset=0&limit=10";
	my $content = get($call);
	printf "i/w/e/c = %d/%d/%d/%d\n",
		$content->{totals}->{info},
		$content->{totals}->{warning},
		$content->{totals}->{error},
		$content->{totals}->{info};
	#print "alerts: ".Dumper($content);
	for my $alert ( @{ $content->{alerts} } ) {
		fmt_alert($alert);
	}
	exit(0);
}
if ($opt_m =~ /^alerts.prune(.*)$/) {
	my $severity = $1;
	printf "\nLooking for severity '%s'\n", $severity;
	print "Booh here I am with opt_m = ".$opt_m."\n";
	my $offset = 0;
	my $limit = 2048;
	_more_alerts:
	my $ids = [ ];
	my $data = { limit => $limit, offset => $offset };
	my $content = get('api/bus/alerts', $data);
	if (!defined $content->{alerts}) {
		#print "No content->{alerts} hmm..\n";
		#print "content = ".Dumper($content);
		#print "res = ".Dumper($gv->{lastres});
		#die "If I search for alerts and find no alerts are there alerts?";
		exit(0);
	}
	printf "i/w/e/c = %d/%d/%d/%d\n",
		$content->{totals}->{info},
		$content->{totals}->{warning},
		$content->{totals}->{error},
		$content->{totals}->{info};
	my @alerts = @{ $content->{alerts} };
	#for my $alert ( grep { $_->{severity} eq $severity } @alerts ) {
	for my $alert ( @alerts ) {
		fmt_alert($alert);
		if ($alert->{severity} eq $severity) {
			printf "id %s matched %s\n", $alert->{id}, $alert->{severity};
			push @$ids, $alert->{id};
		}
	}
	my @foo = @$ids;
	if (@foo) {
		my $dcontent = post('api/bus/alerts/dismiss', $ids);
		print "alerts/dismiss ".$severity."[".($#foo+1)."]: ".Dumper($dcontent)."\n";
	} else {
		print "No $severity to dis-miss\n";
	}
	if ($content->{hasMore} == JSON::true) {
		$offset += $#alerts+1 - ($#foo+1);
		goto _more_alerts;
	}
	exit(0);
}


if ($opt_m eq "rq") { # run queue
	#use Proc::Daemon;
	#Proc::Daemon->init;
	my @pids;
	for $rid (1..$maxrunners) {
		my $fid = fork();
		if ($fid == 0) {
			$0 = "sar runner[$rid]";
			printf "rid %2d starting (pid $$)\n", $rid;
			db_init("dbi:".$dbp->{sqlname}.":".$dbp->{db_name}, $db_user, $db_pass);
			while(1) {
				my $count = run_queue(100);
				printf "rid %2d Uploaded $count blocks\n", $rid;
				if (count_cache() < $maxrunners) {
					sleep(2);
				}
			}
			exit(0);
		}
		push @pids,$fid;
	}
	foreach my $kid (@pids) {
		my $ret = waitpid($kid,0);
		if ($v>0) {
			print "waitpid($kid,0) returned $ret\n";
		}
	}
	exit(0);
}


print "unsupported mode: ${opt_m}\n";
exit(1);

# types of blocks
# dir -> file metadata + pointer
# pointer -> list of blocks
# data -> contents of file


# XXX need to create pointers on the fly vs after all data blocks
#  700mb file took over 15mb of memory

sub archive_file {
    my ($file_path) = @_;
    my @blocks = ();
    my $file_name;
    my $in_fh;
    if (defined($file_path) && $file_path ne "-") {
	$file_name = basename($file_path);
    	open($in_fh, '<', $file_path) or die "Cannot open $file_path: $!";
    	binmode($in_fh);
    } else {
	$in_fh = \*STDIN;
	$file_path = "-";
    }

    my $block_index = 0;
    while(1) {
	my $len = read($in_fh, my $block_data, $block_size);
	printf "read %4d asked for %4d length of data = %4d\n", $len, $block_size, length($block_data);
	if (!defined($len)) {
		die "Cannot read from $file_path: $!";
	}
	if ($len == 0) {
		last;
	}

	my $block_hash = store_block($block_data);        

	add_ptr($block_hash);
    }
    
    close($in_fh);
    my $sha = close_ptr();

    my $data = "file:$file_path\n";
    $data .= "ptr:$sha\n";

    return store_block(mkheader("dir", $data));
}

# XXX turn this into a bg queue via sqlite db?
sub store_block {
	my ($block_data) = @_;
	my $block_hash = sha1_hex($block_data);
	queue_block($block_hash, $block_data);
	return $block_hash;
}
sub queue_block {
	my ($block_hash, $block_data) = @_;
	# XXX best way to not duplicate storing the same block?
	#  - separate select to see if there?
	#  - handle error if insert with constraints?
	#  ... for now, punt, and let head() catch before upload
	my $ret;
	while (1) {
		$ret = count_cache();
		if ($ret < $max_cached_blocks) {
			last;
		}
		sleep(10);
	}
	eval {
		$dbh->do("BEGIN");
		$qbsth->bind_param(1, $block_hash);
		if ($db_type eq "pg") {
			$qbsth->bind_param(2, $block_data, { pg_type => PG_BYTEA });
		} else {
			$qbsth->bind_param(2, $block_data);
		}
		$ret = $qbsth->execute();
		printf "send %4d bytes w/hash %s\n", length($block_data), $block_hash;
		my $vsth = $dbh->prepare("SELECT id,hash,data from bq where hash = ?");
		$vsth->execute($block_hash);
		my $row = $vsth->fetchrow_hashref;
		printf "vrfy %4d bytes w/hash %s\n", length($row->{data}), $row->{hash};
		$vsth->finish();
	};
	if ($@) {
		warn "Error queueing block: $@";
		return;
	}
	if (!defined($ret)) {
		$dbh->do("ROLLBACK");
		return;
	}
	$dbh->do("COMMIT");
}
sub count_cache {
	my $sql = "SELECT COUNT(id) from ".$dbp->{tb_name};
	my $sth = $dbh->prepare($sql);
	$sth->execute();
	my $count = $sth->fetchrow_array();
	return $count;
}
sub run_queue {
	my ($maxcount) = @_;
	if (!defined($maxcount)) {
		$maxcount = 1;
	}
	if ($v>0) {
		warn sprintf("rid %2d run_queue($maxcount)",$rid);
	}
	my $count=0;
	my $ret;
	my $limit = $maxcount * $maxrunners;
	eval {
		$dbh->do("BEGIN");
		$ret = $ubsth->execute($limit);
	};
	if ($@) {
		warn sprintf("rid %2d Error retrieving block: $@",$rid);
		return 0;
	}
	if (!defined($ret)) {
		$dbh->do("ROLLBACK");
		warn sprintf("rid %2d ubsth failed! $! $@",$rid);
		return 0;
	}
	$dbh->do("COMMIT");
	if ($v>0) {
		warn sprintf("rid %2d ubsth->execute($limit) returned $ret",
			$rid);
	}
	while (my $row = $ubsth->fetchrow_hashref) {
		my $id = $row->{id};
		# avoid locking, just only upload when id % maxrunners == runner id
		my $bucket = $id % $maxrunners;
		if ( $bucket != ($rid-1)) {
			if ($v>1) {
			printf "rid %2d row %5d bail %2d % $maxrunners) = $bucket != ".($rid-1)."\n", $rid, $row->{id}, $id;
			}
			next;
		}
		$0 = sprintf("sar runner[%2d] %4d %s", $rid, $row->{id}, $row->{hash});
		printf "rid %2d row %5d handle %4d %s\n", $rid, $row->{id}, length($row->{data}), $row->{hash};;
		$count++;
		my $ret = upload_block($row->{hash}, $row->{data});
		if ($ret) {
			dequeue($row->{id});
		}
		$0 = "sar runner[$rid]";
	}
	return $count;
}
sub dequeue {
	my ($id) = @_;

	my $timeout = $dbp->{timeout};
	my $start_time = time();
	my $retry_count = 0;

	if ($v>0) {
		print "rid $rid $id nuke attempt\n";
	}

	my $success = 0;
	while(time() - $start_time < $timeout) {
		my $ret;
		eval {
			$dbh->do("BEGIN");
			$ret = $rmsth->execute(${id});
		};
		if ($@) {
			my $tsleep = 1.0+rand(2);
			warn "rid $rid $id Error removing ".${id}."from db: $@, will retry in ${tsleep}s";
			sleep($tsleep);
			$retry_count++;
			next;
		}
		if (!defined($ret)) {
			$dbh->do("ROLLBACK");
			next;
		}
		$dbh->do("COMMIT");
		if ($v>1) {
		print "rid $rid $id ret = $ret\n";
		}
		$success++;
		last;
	}
	my $pre = sprintf("rid %2d %5d Operation", $rid, $id);
	if ($success > 0) {
		printf "$pre succeeded after $retry_count retries.\n";
	} else {
		printf "$pre Operation failed.\n";
	}
}
sub upload_block {
	my ($block_hash, $block_data) = @_;
	my $content = head('api/worker/objects/hashes/'.$block_hash);
	if ($gv->{lastres}->is_success) {
		if ($v>0) {
			print " found $block_hash, not re-uploading\n";
		}
		# XXX ? $res->header( 'last-modified' ) # 'Tue, 18 Jun 2024 06:59:03 GMT'
		# XXX ? $res->header( 'etag' ) # '"ec7d3a3630bd9e4ef2a39769b781f761"'
		# if size differs, don't say success
		if ($gv->{lastres}->header( 'content-length' ) == length($block_data)) {
			return 1;
		}
	}
	$content = put('api/worker/objects/hashes/'.$block_hash, $block_data);
	if (!$gv->{lastres}->is_success) {
		warn "Failed to upload $block_hash: ".$gv->{lastres}->status_line;
		return 0;
	}
	if ($v>0) {
		print " put $block_hash\n";
	}
	return 1;
}

sub mkheader {
	my ($type, $data) = @_;
	my $str = "sartype:$type\n";
	$str .= $data;
	return $str;
}
sub init_ablk {
	$ablk->{size} = $hdrsize;
	$ablk->{data} = "";
}

sub add_ptr {
	my ($ptr) = @_;
	my $ptrlen = length($ptr);
	if (!defined($ptr)) {
		next;
	}
	if (($ptrlen + $ablk->{size}) > $block_size) {
		my $sha = store_block( mkheader("ptr", $ablk->{data}));
		init_ablk();
		add_hash($sha);
	}
	add_hash($ptr);
}
sub add_hash {
	my ($hash) = @_;
	$ablk->{data} .= $hash . "\n";
	$ablk->{size} += length($hash);
}
sub close_ptr {
	my ($ptr) = @_;
	my $sha = store_block( mkheader("ptr", $ablk->{data}) );
	init_ablk();
	return $sha;
}

sub restore_file {
    my ($archive_path) = @_;
    my $file_name = basename($archive_path);
    my $restored_file_path = File::Spec->catfile($archive_dir, $file_name . '.restored');
    
    open(my $in_fh, '<', $archive_path) or die "Cannot open $archive_path: $!";
    binmode($in_fh);
    
    open(my $out_fh, '>', $restored_file_path) or die "Cannot create $restored_file_path: $!";
    binmode($out_fh);
    
    while (my $line = <$in_fh>) {
	chomp($line);
	my $block_hash = $line;
	my $block_archive_path = File::Spec->catfile($archive_dir, $block_hash);

	open(my $block_in_fh, '<', $block_archive_path) or die "Cannot open $block_archive_path: $!";
	binmode($block_in_fh);
	    my $block_data;
    read($block_in_fh, $block_data, $block_size) or die "Cannot read from $block_archive_path: $!";
    print $out_fh $block_data;
    }

    close($in_fh);
    close($out_fh);

    return $restored_file_path;
}

sub put {
	my ($cmd, $data) = @_;
	return _call("PUT", $cmd, $data);
}
sub post {
	my ($cmd, $data) = @_;
	return _call("POST", $cmd, $data);
}

sub head {
	my ($cmd) = @_;
	return _call("HEAD", $cmd);
}

sub get {
	my ($cmd, $parms) = @_;
	return _call("GET", $cmd, $parms);
}
sub del {
	my ($cmd) = @_;
	return _call("DELETE", $cmd);
}
sub _call {
	my ($type, $cmd, $data) = @_;
	my $port = $gv->{renterport};
	my $auth = $gv->{AUTH};
	my $bucket = $gv->{renterbucket};
	my $atype = 'text/plain';

	my $baseurl = "http://[::1]:${port}/";
	my $url = $baseurl . $cmd;
	my $parms = { };
	if (ref($data) eq "HASH" && ! ($type =~ /(POST|PUT)/)) {
		$parms = $data;
	} elsif ($type eq "POST") {
		my $json = $gv->{JSON}->encode($data);
		$data = $json;
		$atype = 'application/json';
	}
	$parms->{bucket} = $gv->{renterbucket};
	#printf "_call %s %s %s\n", $type, $cmd, Dumper($parms);
	my $str = "";
	for my $var (keys %{ $parms }) {
		if (!defined $parms->{$var}) {
			next;
		}
		if (length($str) < 1) {
			$str=$str."?${var}=".$parms->{$var};
			next;
		}
		$str=$str."&${var}=".$parms->{$var};
	}
	$url .= $str;
	#printf "_call url=%s\n", $url;
	my $req;

	my $header = [ 'Content-Type' => $atype,
			'Authorization' => $auth ];

	if ($type =~ /(POST|PUT)/) {
		$req = HTTP::Request->new($type => $url, $header, $data);
	} else {
		$req = HTTP::Request->new($type => $url, $header);
	}

	my $res = $ua->request($req);
	$gv->{lastres} = $res;
	my $ret = $res->decoded_content;
	if ($res->is_success) {
		my $cl = $res->header( 'content-length' );
		if (defined $cl && $res->header( 'content-length' ) eq '0') {
			return $ret;
		}
		my $ct = $res->header( 'content-type' );
		if (!defined $ct) {
			print "no content-type header? hrm...\n";
			print Dumper($res);
			die "Bombs away!";
		}
		if ($res->header( 'content-type' ) eq 'application/json') {
			my $json = $gv->{JSON}->decode($ret);
			return $json;
		}
		if ($res->header( 'content-type' ) =~ /^text\/plain/) {
			return $ret;
		}
		print STDERR "Unhandled content-type: ".$res->header( 'content-type' )."\n";
		return $ret;
	}
	return $res;
}

sub db_init {
	my ($cstr, $user, $pass) = @_;
	$dbh = DBI->connect("dbi:".$dbp->{sqlname}.":dbname=".$dbp->{db_name},
		$dbp->{db_user}, $dbp->{db_pass},{
			RaiseError => 0,
			PrintError => 0,
		}) or die "Couldn't connect to database: $DBI::errstr";
	#$dbh->trace(2);

	my $sth = $dbh->prepare("CREATE TABLE IF NOT EXISTS ".$dbp->{tb_name}." ".
		"(id ".$dbp->{serial}.", hash TEXT, data ".$dbp->{blobname}.")");
	$sth->execute() or die "Couldn't create table: $DBI::errstr";
	foreach my $pragma (keys %{ $dbp->{pragmas} }) {
		my $pcmd = "PRAGMA ".$pragma." = ".$dbp->{pragmas}->{$pragma};
		eval {
			$dbh->do($pcmd);
		};
		if ($@) {
			die "Couldn't do($pcmd): $@: $DBI::errstr";
		}
	}
	$qbsth = $dbh->prepare("INSERT INTO ".$dbp->{tb_name}." (hash, data) VALUES (?, ?)");
	$ubsth = $dbh->prepare("SELECT id,hash,data FROM ".$dbp->{tb_name}." ORDER BY id ASC LIMIT ?");
	$rmsth = $dbh->prepare("DELETE FROM ".$dbp->{tb_name}." WHERE id = ?");
}

sub fmt_objects {
	my ($objects) = @_;
	my $hidehealth = 0.1;
	my @olist;
	if (defined $objects->{objects}) {
		@olist = @{ $objects->{objects} };
	} elsif (defined $objects->{entries}) {
		# pre 2.x api
		@olist = @{ $objects->{entries} };
	}
	for my $o (@olist) {
		if ($o->{health} > $hidehealth) {
			next;
		}
		# pre 2.x api
		if (!defined $o->{key}) {
			$o->{key} = $o->{name};
		}
		printf "%5f %12d %s%s\n",
			$o->{health},
			$o->{size},
			$gv->{renterbucket},
			$o->{key};
	}
}
sub listo {
	my ($p, $n) = @_;
	my $minhealth = -0.2;
	my $olimit = 256;

	if (!defined $p) {
		$p = "";
	}
	$p =~ s/^\///;
	if (! ($p =~ /\/$/)) {
		$p .= "/";
		if ($p eq "/") {
			$p = "";
		}
	}
	my $ncount = 0;
	my $recursedir = 1;
	my $recjson;
	if ($recursedir > 0) {
		$recjson = JSON::true;
	} else {
		$recjson = JSON::false;
	}
	_recurse:
	while (1) {
		my $parms = {
			"limit" => 256,
			"prefix" => $p,
			"recursive" => $recjson,
			"delimiter" => "",
			"sortby" => "",
			"sortdir" => "",
			"substring" => "",
			"offset" => $n,
		};
		my $call = 'api/bus/objects/';
		my $content = get($call, $parms);
		if (ref($content) eq "") {
			if ($content =~ /^<.xml version=/) {
				die "Ooops... $content";
			}
			die "Unhandled... $content";
		}
		#print "listo content=".Dumper($content);
		my $objects = $content;
		fmt_objects($objects);
		my @olist;
		if (defined $objects->{objects}) {
			@olist = @{ $objects->{objects} };
		} elsif (defined $objects->{entries}) {
			@olist = @{ $objects->{entries} };
		}
		my $delcount = 0;
		for my $o (@olist) {
			if ($o->{health} < $minhealth) {
				# pre 2.x api
				if (!defined $o->{key}) {
					$o->{key} = $o->{name};
				}
				delo($o->{key});
				$delcount++;
			}
		}
		if (defined $objects->{hasMore} &&
			$objects->{hasMore} == JSON::true) {
			$n += $#olist + 1 - $delcount;
			goto _recurse;
		}
		return $content;
	}
}
sub delo {
	my ($path) = @_;

	$path =~ s/^\///;

	# can't remove dirs
	if ($path =~ /\/$/) {
		return;
	}

	printf "D %s", $path;
	my $content = del('api/bus/object/'.$path);
	print " ".$gv->{lastres}->{_msg}."\n";
	if ($gv->{lastres}->{_msg} eq "Not Found") {
		print "api/bus/object/$path:\n";
		print Dumper($content);
		exit(0);
	}
	return $content;
}
sub fmt_alert {
	my ($a) = @_;
	printf "%s %s %s %s\n", $a->{severity}, $a->{timestamp}, $a->{id}, $a->{message};
	for my $d (sort keys %{ $a->{data} }) {
		printf "        %s = %s\n", $d, $a->{data}->{$d};
	}
}
