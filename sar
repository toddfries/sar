#!/usr/bin/perl

# Copyright (c) 2024 Todd T. Fries <todd@fries.net>
#
# Permission to use, copy, modify, and distribute this software for any
# purpose with or without fee is hereby granted, provided that the above
# copyright notice and this permission notice appear in all copies.
#
# THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
# WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
# MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
# ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
# WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
# ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
# OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.

use strict;
use warnings;
use Digest::SHA1 qw(sha1_hex);
use File::Path qw(make_path);
use File::Spec;
use File::Slurp;
use File::Basename;
use Fcntl qw(SEEK_SET SEEK_CUR SEEK_END);
use Getopt::Std;
use LWP::UserAgent;
use Data::Dumper;
use MIME::Base64;
use DBI;
use Time::HiRes qw(sleep);
use Data::Dumper;

our $opt_m; # mode
our $opt_v; # verbosity
our $opt_d; # db name
our $opt_t; # db type (Pg SQLite)

# defaults
$opt_d = "hashqueue";
$opt_t = "pg";

getopts('d:m:t:v');

if (!defined($opt_m)) {
	die "Need '-m <mode>' where <mode> is one of: t (test), x (extract), c (create)";
}
our $v;
if (defined($opt_v)) {
	$v = $opt_v;
} else {
	$v = 0;
}

my $ua = LWP::UserAgent->new();
$ua->agent('Sia-Agent');

# Configuration
my $block_size = 8 * 1024;
my $archive_dir = '/nhome/todd/sarchive';
my $hashes_dir = $archive_dir . "/hashes";

# Create archive dir if it doesn't exist
make_path($archive_dir) unless -d $archive_dir;
make_path($hashes_dir) unless -d $hashes_dir;

our $hdrsize = length(mkheader("ptr",""));

# memory data
our $ablk = { };
init_ablk();

# for run queue
our $maxrunners = 20;
our $rid; # runner id
our $pid; # process id

my $db_type = $opt_t;

my $db_user = "";
my $db_pass = "";
our $dbp = { };
$dbp->{db_name} = $opt_d;
$dbp->{tb_name} = "bq";
$dbp->{db_user} = "";
$dbp->{db_pass} = "";
$dbp->{timeout} = 100; # in secondts
if ($db_type eq "sqlite") {
	$dbp->{sqlname} = "SQLite";
	$dbp->{serial} = "INTEGER PRIMARY KEY";
	$dbp->{blobname} = "BLOB";
	$dbp->{pragmas}->{busy_timeout} = 1000*$dbp->{timeout};
	$dbp->{pragmas}->{journal_mode} = "WAL";
	$dbp->{pragmas}->{synchronous} = "NORMAL";
}
if ($db_type eq "pg") {
	$dbp->{sqlname} = "Pg";
	$dbp->{serial} = "SERIAL";
	$dbp->{blobname} = "BYTEA";
}
	

# db store
our $dbh;

our ($qbsth,$ubsth,$rmsth);

if ($opt_m eq "c") {
	db_init("dbi:".$dbp->{sqlname}.":".$dbp->{db_name}, $db_user, $db_pass);
	foreach my $path (@ARGV) {
		print "Processing $path\n";
		if (-f $path || $path eq "-") {
			my $sha = archive_file($path);
			print $sha . "\n";
			next;
		}
		#if (-d $path) {
		#	process_dir($path);
		#	next;
		#}
	}
	exit(0);
}

my $pass = $ENV{'renterpass'};
if (!defined($pass)) {
	die "renterpass env not set";
}
our $auth = "Basic " . encode_base64(":$pass","");

if ($opt_m eq "put") {
	my $file = $ARGV[0];
	my $file_content = read_file($file);

	my $res = put('9880',
		'api/worker/objects/name',
		'sarchive',
		$file_content,
		$auth);
	print Dumper($res);
	exit(0);
}

if ($opt_m eq "x") {
	db_init("dbi:".$dbp->{sqlname}.":".$dbp->{db_name}, $db_user, $db_pass);
	foreach my $sha (@ARGV) {
		print "Extracting $sha\n";
		restore_file($sha);
	}
	exit(0);
}

if ($opt_m eq "rq") { # run queue
	#use Proc::Daemon;
	#Proc::Daemon->init;
	my @pids;
	for $rid (1..$maxrunners) {
		my $fid = fork();
		if ($fid == 0) {
			print "rid $rid starting (pid $$)\n";
			db_init("dbi:".$dbp->{sqlname}.":".$dbp->{db_name}, $db_user, $db_pass);
			while(1) {
				my $count = run_queue(100);
				if ($count < 1) {
					last;
				}
				print "rid $rid Uploaded $count blocks\n";
				if (count_cache() < $maxrunners) {
					sleep(2);
				}
			}
			exit(0);
		}
		push @pids,$fid;
	}
	foreach my $kid (@pids) {
		my $ret = waitpid($kid,0);
		if ($v>0) {
			print "waitpid($kid,0) returned $ret\n";
		}
	}
	exit(0);
}


print "unsupported mode: ${opt_m}\n";
exit(1);

# types of blocks
# dir -> file metadata + pointer
# pointer -> list of blocks
# data -> contents of file


# XXX need to create pointers on the fly vs after all data blocks
#  700mb file took over 15mb of memory

sub archive_file {
    my ($file_path) = @_;
    my @blocks = ();
    my $file_name;
    my $in_fh;
    if (defined($file_path) && $file_path ne "-") {
	$file_name = basename($file_path);
    	open($in_fh, '<', $file_path) or die "Cannot open $file_path: $!";
    	binmode($in_fh);
    } else {
	$in_fh = \*STDIN;
	$file_path = "-";
    }
	
    
    my $block_index = 0;
    while(1) {
	my $len = read($in_fh, my $block_data, $block_size);
	printf "read %4d asked for %4d length of data = %4d\n", $len, $block_size, length($block_data);
	if (!defined($len)) {
		die "Cannot read from $file_path: $!";
	}
	if ($len == 0) {
		last;
	}

	my $block_hash = store_block($block_data);        

	add_ptr($block_hash);
    }
    
    close($in_fh);
    my $sha = close_ptr();

    my $data = "file:$file_path\n";
    $data .= "ptr:$sha\n";

    return store_block(mkheader("dir", $data));
}

# XXX turn this into a bg queue via sqlite db?
sub store_block {
	my ($block_data) = @_;
	my $block_hash = sha1_hex($block_data);
	queue_block($block_hash, $block_data);
	return $block_hash;
}
sub queue_block {
	my ($block_hash, $block_data) = @_;
	# XXX best way to not duplicate storing the same block?
	#  - separate select to see if there?
	#  - handle error if insert with constraints?
	#  ... for now, punt, and let head() catch before upload
	my $ret;
	while (1) {
		$ret = count_cache();
		if ($ret < 10000) {
			last;
		}
		sleep(10);
	}
	eval {
		$dbh->do("BEGIN");
		$ret = $qbsth->execute($block_hash, $block_data);
	};
	if ($@) {
		warn "Error queueing block: $@";
		return;
	}
	if (!defined($ret)) {
		$dbh->do("ROLLBACK");
		return;
	}
	$dbh->do("COMMIT");
}
sub count_cache {
	my $sql = "SELECT COUNT(id) from ".$dbp->{tb_name};
	my $sth = $dbh->prepare($sql);
	$sth->execute();
	my $count = $sth->fetchrow_array();
	return $count;
}
sub run_queue {
	my ($maxcount) = @_;
	if (!defined($maxcount)) {
		$maxcount = 1;
	}
	if ($v>0) {
		warn "rid $rid run_queue($maxcount)";
	}
	my $count=0;
	my $ret;
	my $limit = $maxcount * $maxrunners;
	eval {
		$dbh->do("BEGIN");
		$ret = $ubsth->execute($limit);
	};
	if ($@) {
		warn "rid $rid Error retrieving block: $@";
		return 0;
	}
	if (!defined($ret)) {
		$dbh->do("ROLLBACK");
		warn "rid $rid ubsth failed! $! $@";
		return 0;
	}
	$dbh->do("COMMIT");
	if ($v>0) {
		warn "rid $rid ubsth->execute($limit) returned $ret";
	}
	while (my $row = $ubsth->fetchrow_hashref) {
		my $id = $row->{id};
		# avoid locking, just only upload when id % maxrunners == runner id
		my $bucket = $id % $maxrunners;
		if ( $bucket != ($rid-1)) {
			if ($v>1) {
			print "rid $rid row ".$row->{id}." bail $id % $maxrunners) = $bucket != ".($rid-1)."\n";
			}
			next;
		}
		printf "rid $rid row ".$row->{id}." handle %4d %s\n", length($row->{data}), $row->{hash};;
		$count++;
		my $ret = upload_block($row->{hash}, $row->{data});
		if ($ret) {
			dequeue($row->{id});
		}
	}
	return $count+1;
}
sub dequeue {
	my ($id) = @_;

	my $timeout = $dbp->{timeout};
	my $start_time = time();
	my $retry_count = 0;

	if ($v>0) {
		print "rid $rid $id nuke attempt\n";
	}

	my $success = 0;
	while(time() - $start_time < $timeout) {
		my $ret;
		eval {
			$dbh->do("BEGIN");
			$ret = $rmsth->execute(${id});
		};
		if ($@) {
			my $tsleep = 1.0+rand(2);
			warn "rid $rid $id Error removing ".${id}."from db: $@, will retry in ${tsleep}s";
			sleep($tsleep);
			$retry_count++;
			next;
		}
		if (!defined($ret)) {
			$dbh->do("ROLLBACK");
			next;
		}
		$dbh->do("COMMIT");
		if ($v>1) {
		print "rid $rid $id ret = $ret\n";
		}
		$success++;
		last;
	}
	if ($success > 0) {
		print "rid $rid $id Operation succeeded after $retry_count retries.\n";
	} else {
		print "rid $rid $id Operation failed.\n";
	}
}
sub upload_block {
	my ($block_hash, $block_data) = @_;
	if (head('9880',
		'api/worker/objects/hashes/'.$block_hash,
		'sarchive',
		$auth)) {
		if ($v>0) {
			print " found $block_hash, not re-uploading\n";
		}
		return 1;
	}
	my $res = put('9880',
		'api/worker/objects/hashes/'.$block_hash,
		'sarchive',
		$block_data,
		$auth);
	if (!$res->is_success) {
		warn "Failed to upload $block_hash: ".$res->status_line;
		return 0;
	}
	if ($v>0) {
		print " put $block_hash\n";
	}
	return 1;
}

sub mkheader {
	my ($type, $data) = @_;
	my $str = "sartype:$type\n";
	$str .= $data;
	return $str;
}
sub init_ablk {
	$ablk->{size} = $hdrsize;
	$ablk->{data} = "";
}
	
sub add_ptr {
	my ($ptr) = @_;
	my $ptrlen = length($ptr);
	if (!defined($ptr)) {
		next;
	}
	if (($ptrlen + $ablk->{size}) > $block_size) {
		my $sha = store_block( mkheader("ptr", $ablk->{data}));
		init_ablk();
		add_hash($sha);
	}
	add_hash($ptr);
}
sub add_hash {
	my ($hash) = @_;
	$ablk->{data} .= $hash . "\n";
	$ablk->{size} += length($hash);
}
sub close_ptr {
	my ($ptr) = @_;
	my $sha = store_block( mkheader("ptr", $ablk->{data}) );
	init_ablk();
	return $sha;
}

sub restore_file {
    my ($archive_path) = @_;
    my $file_name = basename($archive_path);
    my $restored_file_path = File::Spec->catfile($archive_dir, $file_name . '.restored');
    
    open(my $in_fh, '<', $archive_path) or die "Cannot open $archive_path: $!";
    binmode($in_fh);
    
    open(my $out_fh, '>', $restored_file_path) or die "Cannot create $restored_file_path: $!";
    binmode($out_fh);
    
    while (my $line = <$in_fh>) {
	chomp($line);
	my $block_hash = $line;
	my $block_archive_path = File::Spec->catfile($archive_dir, $block_hash);
	
	open(my $block_in_fh, '<', $block_archive_path) or die "Cannot open $block_archive_path: $!";
	binmode($block_in_fh);
	    my $block_data;
    read($block_in_fh, $block_data, $block_size) or die "Cannot read from $block_archive_path: $!";
    print $out_fh $block_data;
    }

    close($in_fh);
    close($out_fh);

    return $restored_file_path;
}

sub put {
	my ($port, $cmd, $bucket, $data, $auth) = @_;

	my $baseurl = "http://[::1]:${port}/";
	my $url = $baseurl . $cmd . "?bucket=$bucket";
	my $encoded_data;
	my $req;

	my $header = [ 'Content-Type' => 'text/plain',
			'Authorization' => $auth ];

	$req = HTTP::Request->new(PUT => $url,
			$header,
			$data);

	my $res = $ua->request($req);
	return $res;
}

sub head {
	my ($port, $cmd, $bucket, $auth) = @_;

	my $baseurl = "http://[::1]:${port}/";
	my $url = $baseurl . $cmd . "?bucket=$bucket";
	my $encoded_data;
	my $req;

	my $header = [ 'Content-Type' => 'text/plain',
			'Authorization' => $auth ];

	$req = HTTP::Request->new(HEAD => $url,
			$header);

	my $res = $ua->request($req);
	return $res->is_success;
}

sub db_init {
	my ($cstr, $user, $pass) = @_;
	$dbh = DBI->connect("dbi:".$dbp->{sqlname}.":dbname=".$dbp->{db_name},
		$dbp->{db_user}, $dbp->{db_pass},{
			RaiseError => 0,
			PrintError => 0,
		}) or die "Couldn't connect to database: $DBI::errstr";
	#$dbh->trace(2);

	my $sth = $dbh->prepare("CREATE TABLE IF NOT EXISTS ".$dbp->{tb_name}." ".
		"(id ".$dbp->{serial}.", hash TEXT, data ".$dbp->{blobname}.")");
	$sth->execute() or die "Couldn't create table: $DBI::errstr";
	foreach my $pragma (keys %{ $dbp->{pragmas} }) {
		my $pcmd = "PRAGMA ".$pragma." = ".$dbp->{pragmas}->{$pragma};
		eval {
			$dbh->do($pcmd);
		};
		if ($@) {
			die "Couldn't do($pcmd): $@: $DBI::errstr";
		}
	}
	$qbsth = $dbh->prepare("INSERT INTO ".$dbp->{tb_name}." (hash, data) VALUES (?, ?)");
	$ubsth = $dbh->prepare("SELECT id,hash,data FROM ".$dbp->{tb_name}." ORDER BY id ASC LIMIT ?");
	$rmsth = $dbh->prepare("DELETE FROM ".$dbp->{tb_name}." WHERE id = ?");
}
